#         }
#         doc <- data.frame(doc[[1]])
#         doc <- doc[1]
#         colnames(doc)[1] <- 'Document Name'
#         if (i == 6) flash_list <- doc
#         else flash_list <- rbind(flash_list, doc)
#     }
#     names(flash_list) <- 'Document Name'
#     flash_list$appeal_type <- 'Flash Appeal'
#
# Other appeals from page 8 until page 9
message('Assembling a list of other appeals documents.')
pb <- txtProgressBar(min = 8, max = 9, style = 3)
for(i in 8:9){
if (verbose == TRUE) message(paste('Page:', i))
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
if (i == 8) {
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
}
else {
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
}
doc <- data.frame(doc[[1]])
#         doc <- doc[1]
colnames(doc)[1] <- 'Document Name'
if (i == 8) other_list <- doc
else other_list <- rbind(other_list, doc)
}
names(other_list) <- 'Document Name'
other_list$appeal_type <- 'Other'
x <<- other_list
message('Done.')
z_list <- rbind(cap_list, flash_list, other_list)
return(z_list)
}
list <- downloadAppeals()
base_url <- 'http://www.unocha.org/cap/appeals/by-appeal/results'
page <- '?page='  # 492 appeals in 11 pages -- starts at 0.
url <- paste0(base_url, page, 8)
url
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
VieW(doc)
View(doc)
doc <- doc[1]
View(doc)
colnames(doc)[1] <- 'Document Name'
other_list <- doc
View(other_list)
url <- paste0(base_url, page, 9)
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- doc[1]
colnames(doc)[1] <- 'Document Name'
View(doc)
doc <- doc[1]
VieW(doc)
View(doc)
colnames(doc)[1] <- 'Document Name'
View(doc)
doc <- doc[1]
View(doc)
doc[1]
class(doc)
doc[[1]]
length(doc)
length(doc[[1]])
length(doc[[1]][[1]])
table <- getNodeSet(htmlParse(url),"//table")
doc <- readHTMLTable(table, useInternal = TRUE)
doc <- readHTMLTable(table, useInternal = TRUE)
table
downloadAppeals <- function(verbose = FALSE) {
base_url <- 'http://www.unocha.org/cap/appeals/by-appeal/results'
page <- '?page='  # 492 appeals in 11 pages -- starts at 0.
#     message('Assembling a list of CAP documents.')
#     pb <- txtProgressBar(min = 0, max = 6, style = 3)
#     # CAP appeals go until page 6
#     for(i in 0:6) {
#         if (verbose == TRUE) message(paste('Page:', i))
#         setTxtProgressBar(pb, i)
#         url <- paste0(base_url, page, i)
#         doc <- readHTMLTable(getURL(url), useInternal = TRUE)
#         doc <- data.frame(doc)
#         doc <- doc[1]
#         colnames(doc)[1] <- 'Document Name'
#         if (i == 0) cap_list <- doc
#         else cap_list <- rbind(cap_list, doc)
#     }
#     names(cap_list) <- 'Document Name'
#     cap_list$appeal_type <- 'Consolidated Appeal'
#
#     # Flash appeals from page 6 until page 8
#     message('Assembling a list of Flash appeals documents.')
#     if (verbose == TRUE) message(paste('Page:', i))
#     pb <- txtProgressBar(min = 6, max = 8, style = 3)
#     for(i in 6:8){
#         setTxtProgressBar(pb, i)
#         url <- paste0(base_url, page, i)
#         if (i == 6) {
#             table <- getNodeSet(htmlParse(url),"//table")[[2]]
#             doc <- readHTMLTable(table, useInternal = TRUE)
#         }
#         else {
#             doc <- readHTMLTable(getURL(url), useInternal = TRUE)
#         }
#         doc <- data.frame(doc[[1]])
#         doc <- doc[1]
#         colnames(doc)[1] <- 'Document Name'
#         if (i == 6) flash_list <- doc
#         else flash_list <- rbind(flash_list, doc)
#     }
#     names(flash_list) <- 'Document Name'
#     flash_list$appeal_type <- 'Flash Appeal'
#
# Other appeals from page 8 until page 9
message('Assembling a list of other appeals documents.')
pb <- txtProgressBar(min = 8, max = 9, style = 3)
for(i in 8:9){
if (verbose == TRUE) message(paste('Page:', i))
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
if (i == 8) {
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
doc <- doc[1]
}
else {
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- doc[[1]][[1]]
}
colnames(doc)[1] <- 'Document Name'
if (i == 8) other_list <- doc
else other_list <- rbind(other_list, doc)
}
names(other_list) <- 'Document Name'
other_list$appeal_type <- 'Other'
x <<- other_list
message('Done.')
z_list <- rbind(cap_list, flash_list, other_list)
return(z_list)
}
list <- downloadAppeals()
url
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- doc[[1]][[1]]
View(doc)
colnames(doc)[1] <- 'Document Name'
doc <- data.frame(doc[[1]][[1]])
colnames(doc)[1] <- 'Document Name'
View(doc)
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- data.frame(doc[[1]])
View(doc)
colnames(doc)[1] <- 'Document Name'
View(doc)
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- data.frame(doc[[1]])
doc <- doc[1]
colnames(doc)[1] <- 'Document Name'
View(doc)
downloadAppeals <- function(verbose = FALSE) {
base_url <- 'http://www.unocha.org/cap/appeals/by-appeal/results'
page <- '?page='  # 492 appeals in 11 pages -- starts at 0.
#     message('Assembling a list of CAP documents.')
#     pb <- txtProgressBar(min = 0, max = 6, style = 3)
#     # CAP appeals go until page 6
#     for(i in 0:6) {
#         if (verbose == TRUE) message(paste('Page:', i))
#         setTxtProgressBar(pb, i)
#         url <- paste0(base_url, page, i)
#         doc <- readHTMLTable(getURL(url), useInternal = TRUE)
#         doc <- data.frame(doc)
#         doc <- doc[1]
#         colnames(doc)[1] <- 'Document Name'
#         if (i == 0) cap_list <- doc
#         else cap_list <- rbind(cap_list, doc)
#     }
#     names(cap_list) <- 'Document Name'
#     cap_list$appeal_type <- 'Consolidated Appeal'
#
#     # Flash appeals from page 6 until page 8
#     message('Assembling a list of Flash appeals documents.')
#     if (verbose == TRUE) message(paste('Page:', i))
#     pb <- txtProgressBar(min = 6, max = 8, style = 3)
#     for(i in 6:8){
#         setTxtProgressBar(pb, i)
#         url <- paste0(base_url, page, i)
#         if (i == 6) {
#             table <- getNodeSet(htmlParse(url),"//table")[[2]]
#             doc <- readHTMLTable(table, useInternal = TRUE)
#         }
#         else {
#             doc <- readHTMLTable(getURL(url), useInternal = TRUE)
#         }
#         doc <- data.frame(doc[[1]])
#         doc <- doc[1]
#         colnames(doc)[1] <- 'Document Name'
#         if (i == 6) flash_list <- doc
#         else flash_list <- rbind(flash_list, doc)
#     }
#     names(flash_list) <- 'Document Name'
#     flash_list$appeal_type <- 'Flash Appeal'
#
# Other appeals from page 8 until page 9
message('Assembling a list of other appeals documents.')
pb <- txtProgressBar(min = 8, max = 9, style = 3)
for(i in 8:9){
if (verbose == TRUE) message(paste('Page:', i))
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
if (i == 8) {
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
doc <- doc[1]
}
else {
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- data.frame(doc[[1]])
doc <- doc[1]
}
colnames(doc)[1] <- 'Document Name'
if (i == 8) other_list <- doc
else other_list <- rbind(other_list, doc)
}
names(other_list) <- 'Document Name'
other_list$appeal_type <- 'Other'
x <<- other_list
message('Done.')
z_list <- rbind(cap_list, flash_list, other_list)
return(z_list)
}
list <- downloadAppeals()
View(x)
downloadAppeals <- function(verbose = FALSE) {
base_url <- 'http://www.unocha.org/cap/appeals/by-appeal/results'
page <- '?page='  # 492 appeals in 11 pages -- starts at 0.
message('Assembling a list of CAP documents.')
pb <- txtProgressBar(min = 0, max = 6, style = 3)
# CAP appeals go until page 6
for(i in 0:6) {
if (verbose == TRUE) message(paste('Page:', i))
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- data.frame(doc)
doc <- doc[1]
colnames(doc)[1] <- 'Document Name'
if (i == 0) cap_list <- doc
else cap_list <- rbind(cap_list, doc)
}
names(cap_list) <- 'Document Name'
cap_list$appeal_type <- 'Consolidated Appeal'
# Flash appeals from page 6 until page 8
message('Assembling a list of Flash appeals documents.')
if (verbose == TRUE) message(paste('Page:', i))
pb <- txtProgressBar(min = 6, max = 8, style = 3)
for(i in 6:8){
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
if (i == 6) {
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
}
else {
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
}
doc <- data.frame(doc[[1]])
doc <- doc[1]
colnames(doc)[1] <- 'Document Name'
if (i == 6) flash_list <- doc
else flash_list <- rbind(flash_list, doc)
}
names(flash_list) <- 'Document Name'
flash_list$appeal_type <- 'Flash Appeal'
# Other appeals from page 8 until page 9
message('Assembling a list of other appeals documents.')
pb <- txtProgressBar(min = 8, max = 9, style = 3)
for(i in 8:9){
if (verbose == TRUE) message(paste('Page:', i))
setTxtProgressBar(pb, i)
url <- paste0(base_url, page, i)
if (i == 8) {
table <- getNodeSet(htmlParse(url),"//table")[[2]]
doc <- readHTMLTable(table, useInternal = TRUE)
doc <- doc[1]
}
else {
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc <- data.frame(doc[[1]])
doc <- doc[1]
}
colnames(doc)[1] <- 'Document Name'
if (i == 8) other_list <- doc
else other_list <- rbind(other_list, doc)
}
names(other_list) <- 'Document Name'
other_list$appeal_type <- 'Other appeals'
x <<- other_list
message('Done.')
z_list <- rbind(cap_list, flash_list, other_list)
return(z_list)
}
list <- downloadAppeals()
# writing CSV.
write.csv(list, 'data/appeals_list.csv', row.names = F)
setwd("~/Documents/Programming/cap_appeals")
write.csv(list, 'data/appeals_list.csv', row.names = F)
library(countrycode)
names(list)
list$iso3 <- countrycode(list[1], 'country.name', 'iso3c')
View(list)
names(list) <- c('document_name', 'appeal_type')
list$iso3 <- countrycode(list$document_name, 'country.name', 'iso3c')
View(list)
names(list)
list$NA <- NA
list[3] <-NULL
names(list)
summary(is.na(list$iso3))
qplot(list$iso3c)
library(ggplot2)
library(ggplot2)
qplot(list$iso3c)
ggplot(list) + geom_bar(aes(iso3), stat = 'bin')
ggplot(na.omit(list)) + geom_bar(aes(iso3), stat = 'bin')
?grepl
regexpr('[^,]*$', df$document_name)
df$document_name
regexpr('[^,]*$', list$document_name)
gregexpr('[^,]*$', list$document_name)
regexec('[^,]*$', list$document_name)
gregexpr('[^,]*$', list$document_name)
gsub('[^,]*$', list$document_name)
gsub('[^,]*$', "\\1", list$document_name)
gsub('^(.+?),', "\\1", list$document_name)
gsub('^(.+?),', "", list$document_name)
gsub('[^,]*$', "\\1", list$document_name)
gsub('[^,]*$', "", list$document_name)
gsub('[^,]*$', " ", list$document_name)
gsub('[^,]*$', "\\1", list$document_name)
gsub('(.+?),', "", list$document_name)
x <- encodeTime(list)
encodeTime <- function(df = NULL) {
df$date <- gsub('(.+?),', "", df$document_name)
# [^,]*$ everything after the last comma
}
x <- encodeTime(list)
encodeTime <- function(df = NULL) {
df$date <- gsub('(.+?),', "", df$document_name)
# [^,]*$ everything after the last comma
return(df)
}
x <- encodeTime(list)
View(x)
encodeTime <- function(df = NULL) {
# returns only the dates strings (after the last comma)
df$date <- gsub('(.+?),', "", df$document_name)
# returns string w/o leading or trailing whitespace
df$date <- gsub("^\\s+|\\s+$", "", df$date)
return(df)
}
x <- encodeTime(list)
View(x)
as.Date(x$date)
?as.Date
View(x)
encodeTime <- function(df = NULL) {
# returns only the dates strings (after the last comma)
df$date <- gsub('(.+?),', "", df$document_name)
# returns string w/o leading or trailing whitespace
df$date <- gsub("^\\s+|\\s+$", "", df$date)
# returns a date class
df$date <- as.Date(df$date, format = "%d %b %Y")
return(df)
}
x <- encodeTime(list)
View(x)
ggplot(list) + geom_line(aes(date), stat = 'bn')
ggplot(list) + geom_line(aes(date), stat = 'bin')
ggplot(x) + geom_line(aes(date), stat = 'bin')
names(x)
ggplot(x) + geom_line(aes(date), stat = 'bin') + facet_wrap(~ appeal_type)
list$id <- paste0('CAP-', 001:nrow(list))
View(list)
url
base_url <- 'http://www.unocha.org/cap/appeals/by-appeal/results'
page <- '?page='  # 492 appeals in 11 pages -- starts at 0.
url <- paste0(base_url, page, 1)
url
doc <- readHTMLTable(getURL(url), useInternal = TRUE)
doc
table <- getNodeSet(htmlParse(url),"//table")[[1]]
table
x <- getNodeSet(table, "//a")
x
lenght(x)
length(x)
View(x)
x <- getNodeSet(htmlParse(table), "//a")
x <- getNodeSet(table, "//a", useInternal = TRUE)
x <- getNodeSet(table, "//a")
x
nrow(list)
sitePage<-htmlParse("http://ipt.humboldt.org.co/")
hyperlinksYouNeed<-getNodeSet(sitePage,"//table[@id='resourcestable']
//td[5][.='Specimen']
/preceding-sibling
::td[3]
/a
/@href")
View(hyperlinksYouNeed)
hyperlinksYouNeed
url <- paste0(base_url, page, 1)
hyperlinksYouNeed<-getNodeSet(url,"//table[2]
//td[2][.='Document']
/a
/@href")
hyperlinksYouNeed<-getNodeSet(getURL(url),"//table[2]
//td[2][.='Document']
/a
/@href")
doc <- getNodeSet(getURL(url))
url
doc <- getNodeSet(getURL(url))
doc <- getNodeSet(url)
getNodeSet(htmlParse(url),"//table")
hyperlinksYouNeed <- getNodeSet(getURL(url),"//table[2]
//td[2][.='Document']
/a
/@href")
hyperlinksYouNeed <- getNodeSet(getURL(url),"//table[2]")
getNodeSet(htmlParse(url),"//table")
#### Extracting Links  ####
url <- paste0(base_url, page, 1)
doc <- getNodeSet(url)
doc <- getNodeSet(url)
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table[2]
//td[2][.='Document']
/a
/@href")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table[2]
//td[2]
/a
/@href")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table[2]
//td[2]")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table[2]
//td")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td[2]")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td[2]
/a
/@href ")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td[2]
/a
/@href[1]")
hyperlinksYouNeed
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td[2]
/a
/@href[[1]]")
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td[2]
/a
/@href[1]")
hyperlinksYouNeed
hyperlinksYouNeed[[1]]
as.character(hyperlinksYouNeed[[1]])
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td
/a
/@href")
hyperlinksYouNeed <- getNodeSet(htmlParse(url),"//table
//td
/a
/@href")
hyperlinksYouNeed
View(hyperlinksYouNeed)
hyperlinksYouNeed
hyperlinksYouNeed[[1]]
hyperlinksYouNeed[[2]]
hyperlinksYouNeed[2]
hyperlinksYouNeed[3]
hyperlinksYouNeed[4]
hyperlinksYouNeed[5]
hyperlinksYouNeed[6]
class(hyperlinksYouNeed)
?
readHTMLTable
xmlTreeParse(hyperlinksYouNeed)
unclass(hyperlinksYouNeed)
x <- unclass(hyperlinksYouNeed)
class(x)
View(x)
x[1]
as.data.frame(x)
x[1]
x$href
x[1$href
